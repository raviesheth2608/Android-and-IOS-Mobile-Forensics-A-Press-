{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5ec1181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 1: Delete the chat logs before the police check your phone.\n",
      "  Tokens   : ['delete', 'the', 'chat', 'logs', 'before', 'the', 'police', 'check', 'your', 'phone']\n",
      "  Sentiment: 0.0\n",
      "  Entities : ['Delete']\n",
      "\n",
      "Text 2: Meet at the abandoned warehouse at midnight. Don't tell anyone.\n",
      "  Tokens   : ['meet', 'at', 'the', 'abandoned', 'warehouse', 'at', 'midnight', 'don', 't', 'tell', 'anyone']\n",
      "  Sentiment: 0.0\n",
      "  Entities : ['Meet', 'Don']\n",
      "\n",
      "Text 3: Send me the bank account details through WhatsApp, keep it secret.\n",
      "  Tokens   : ['send', 'me', 'the', 'bank', 'account', 'details', 'through', 'whatsapp', 'keep', 'it', 'secret']\n",
      "  Sentiment: -0.4\n",
      "  Entities : ['Send', 'WhatsApp']\n",
      "\n",
      "Text 4: I wiped the SIM card, no one will find the messages.\n",
      "  Tokens   : ['i', 'wiped', 'the', 'sim', 'card', 'no', 'one', 'will', 'find', 'the', 'messages']\n",
      "  Sentiment: 0.0\n",
      "  Entities : ['SIM']\n",
      "\n",
      "Text 5: The package will be dropped near Central Station tomorrow night.\n",
      "  Tokens   : ['the', 'package', 'will', 'be', 'dropped', 'near', 'central', 'station', 'tomorrow', 'night']\n",
      "  Sentiment: 0.05\n",
      "  Entities : ['The', 'Central', 'Station']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'tokens': ['delete',\n",
       "   'the',\n",
       "   'chat',\n",
       "   'logs',\n",
       "   'before',\n",
       "   'the',\n",
       "   'police',\n",
       "   'check',\n",
       "   'your',\n",
       "   'phone'],\n",
       "  'sentiment': 0.0,\n",
       "  'entities': ['Delete']},\n",
       " {'tokens': ['meet',\n",
       "   'at',\n",
       "   'the',\n",
       "   'abandoned',\n",
       "   'warehouse',\n",
       "   'at',\n",
       "   'midnight',\n",
       "   'don',\n",
       "   't',\n",
       "   'tell',\n",
       "   'anyone'],\n",
       "  'sentiment': 0.0,\n",
       "  'entities': ['Meet', 'Don']},\n",
       " {'tokens': ['send',\n",
       "   'me',\n",
       "   'the',\n",
       "   'bank',\n",
       "   'account',\n",
       "   'details',\n",
       "   'through',\n",
       "   'whatsapp',\n",
       "   'keep',\n",
       "   'it',\n",
       "   'secret'],\n",
       "  'sentiment': -0.4,\n",
       "  'entities': ['Send', 'WhatsApp']},\n",
       " {'tokens': ['i',\n",
       "   'wiped',\n",
       "   'the',\n",
       "   'sim',\n",
       "   'card',\n",
       "   'no',\n",
       "   'one',\n",
       "   'will',\n",
       "   'find',\n",
       "   'the',\n",
       "   'messages'],\n",
       "  'sentiment': 0.0,\n",
       "  'entities': ['SIM']},\n",
       " {'tokens': ['the',\n",
       "   'package',\n",
       "   'will',\n",
       "   'be',\n",
       "   'dropped',\n",
       "   'near',\n",
       "   'central',\n",
       "   'station',\n",
       "   'tomorrow',\n",
       "   'night'],\n",
       "  'sentiment': 0.05,\n",
       "  'entities': ['The', 'Central', 'Station']}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "def extract_text_features(text_series):\n",
    "    \"\"\"\n",
    "       text_series: pandas Series or list of text messages/emails\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for i, text in enumerate(text_series):\n",
    "        if not isinstance(text, str):\n",
    "            text = \"\"\n",
    "        \n",
    "        # Sentiment Analysis\n",
    "        blob = TextBlob(text)\n",
    "        sentiment = blob.sentiment.polarity  # -1 to 1\n",
    "\n",
    "        # Tokenization\n",
    "        tokens = [word for word in re.findall(r'\\w+', text.lower())]\n",
    "\n",
    "        # Simple Entity Extraction (using regex: capitalized words)\n",
    "        entities = re.findall(r'\\b[A-Z][a-zA-Z]+\\b', text)\n",
    "\n",
    "        # Collect features\n",
    "        feature_dict = {\n",
    "            \"tokens\": tokens,\n",
    "            \"sentiment\": sentiment,\n",
    "            \"entities\": entities\n",
    "        }\n",
    "        features.append(feature_dict)\n",
    "\n",
    "        # --- Display results ---\n",
    "        print(f\"\\nText {i+1}: {text}\")\n",
    "        print(f\"  Tokens   : {tokens}\")\n",
    "        print(f\"  Sentiment: {sentiment}\")\n",
    "        print(f\"  Entities : {entities}\")\n",
    "\n",
    "    return features\n",
    "\n",
    "sample_texts = [\n",
    "    \"Delete the chat logs before the police check your phone.\",\n",
    "    \"Meet at the abandoned warehouse at midnight. Don't tell anyone.\",\n",
    "    \"Send me the bank account details through WhatsApp, keep it secret.\",\n",
    "    \"I wiped the SIM card, no one will find the messages.\",\n",
    "    \"The package will be dropped near Central Station tomorrow night.\"\n",
    "]\n",
    "\n",
    "extract_text_features(sample_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9af2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
